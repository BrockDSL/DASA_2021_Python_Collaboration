{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Machine Learning Basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bif0tsBDxtIr"
      },
      "source": [
        "![DSL_logo](https://github.com/BrockDSL/Machine_Learning_with_Python/blob/master/dsl_logo.png?raw=1)\n",
        "\n",
        "# Introduction to Machine Learning with Python\n",
        "\n",
        "\n",
        "In our [Data Science](https://brockdsl.github.io/Python_2.0_Workshop/) workshop we introduced some concepts by looking at some fictional data about wine samples that were rated a quality score. In this session we are going to see if we can build a machine learning model to see if we can predict which wine sample is rated the highest quality based on the answers to some questions. \n",
        "\n",
        "As a further exercise we'll setup an example of a two layer neural network. I encourage you to try out this examples after class is done.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6PZm1dKxtIw"
      },
      "source": [
        "## First, a brief recap on Python code\n",
        "\n",
        "The following code should look familiar to you"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHQNPWMZxtIx"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the file into a dataframe using the pandas read_csv function\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "\n",
        "#Tell it what our columns are by passing along a list of that information\n",
        "data.columns = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
        "\n",
        "print(\"Poor Quality or High Quality?\")\n",
        "print(data.groupby(\"quality\")[\"citric acid\"].count())\n",
        "print(\"\\nTotal records:\", len(data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xXF7W2lxtIy"
      },
      "source": [
        "## Machine Learning Basics\n",
        "\n",
        "Don't let the impressive name fool you. Machine learning is more or less the following steps\n",
        "\n",
        "1. Getting your data and cleaning it up\n",
        "1. Identify what parts of your data are **features**\n",
        "1. Identify what is your **target variable** that you'll guess based on your features\n",
        "1. Split your data in **training and testing sets**\n",
        "1. **Train** your model against the training set\n",
        "1. **Validate** your model against the testing set\n",
        "1. ????\n",
        "1. Profit\n",
        "\n",
        "\n",
        "We are going to use the Python library [scikit-learn](https://scikit-learn.org/stable/) and we are going to be doing a [classification](https://en.wikipedia.org/wiki/Statistical_classification) problem.\n",
        "\n",
        "![classification](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/classification.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV3QmkVcxtIz"
      },
      "source": [
        "## Decision Tree\n",
        "\n",
        "This is one of the most basic machine learning model you can use. It is considered a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) method. You create the best [decision tree](https://en.wikipedia.org/wiki/Decision_tree_learning) that you can based on your training data. Here's an example tree that shows your chance of surviving the Titanic disaster. What we are creating is series of question that when answered will put observations into a _bucket_ or in other terms one of the classification options. We also devise a probability associated with an observation falling into that _bucket_.\n",
        "\n",
        "The features are described by the labels, however ``sibsp`` - is the number of spouses or siblings on board.\n",
        "\n",
        "![dtree](https://upload.wikimedia.org/wikipedia/commons/e/eb/Decision_Tree.jpg)\n",
        "\n",
        "\n",
        "So in this tree the most important question to ask first is what is the gender of the person you are considering, then next most important question is age above 9 and a half, followed lastly by, does this person have less than three spouses or siblings on board.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo9ZhkUjxtI0"
      },
      "source": [
        "Let's start by loading the Libraries we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB_qUWNMxtI1"
      },
      "source": [
        "#We'll draw a graph later on\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Our 'Machine Learning pieces'\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import export_text\n",
        "from sklearn import metrics \n",
        "from sklearn import tree\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3qQyaGIxtI2"
      },
      "source": [
        "## Getting the data ready\n",
        "\n",
        "Now, let's load our data. Our decision tree can only work with numerical values, so we'll have to modify the columns of data that are text based. As stated preparing the data is usually the most difficult part of the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-D7eb-kxtI2"
      },
      "source": [
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "data.columns = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK-S0JNHxtI5"
      },
      "source": [
        "## Building and Running the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYDN-8jLxtI5"
      },
      "source": [
        "We now have our data cleaned up, and represented in a way that Scikit will be able to analyze. To be honest the most difficult part of the process is done.\n",
        "\n",
        "We now need to split our columns in two types:\n",
        "- **features** represent the data we use to build our guess\n",
        "- **target variable** the thing our model hopes to guess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa1meCmOxtI6"
      },
      "source": [
        "#all of the following columns are features, we'll make a list of their names\n",
        "features = [\"fixed acidity\",\\\n",
        "            \"volatile acidity\",\\\n",
        "            \"citric acid\",\\\n",
        "            \"residual sugar\",\\\n",
        "            \"chlorides\",\n",
        "            \"free sulfur dioxide\",\\\n",
        "            \"total sulfur dioxide\",\\\n",
        "            \"density\",\n",
        "            \"pH\",\\\n",
        "            \"sulphates\",\\\n",
        "            \"alcohol\",\\\n",
        "            ]\n",
        "\n",
        "X = data[features]\n",
        "\n",
        "#We want to target the quality column\n",
        "y = data.quality"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhruO3UHxtI7"
      },
      "source": [
        "\n",
        "## Training and testing\n",
        "\n",
        "Now that we have built our model we need to get the data ready for it. We do this by breaking it into two different pieces. The diagram shows a conceptualization of how this is proportioned.\n",
        "\n",
        "![Train Test Split](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/train_test.png)\n",
        "\n",
        "- **Training set** this is what is used to build the model\n",
        "- **Testing set** this is used to see if our guesses are correct\n",
        "\n",
        "Before we were looking at the **columns** of the data, this investigation of training/testing looks at the **rows** of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p-MRbnwxtI7"
      },
      "source": [
        "#Training and test together make up 100% of the data!\n",
        "#We start with a baseline of 30% of our data as testing\n",
        "\n",
        "test_percent = 30\n",
        "train_percent = 100 - test_percent\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
        "                                                    y, \\\n",
        "                                                    test_size=test_percent/100.0,\n",
        "                                                   random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjlsU2pTxtI7"
      },
      "source": [
        "Now the interesting part, we build our model, **train** it against the **training set** and see how it **predicts** against the **testing set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6malq8NxtI8"
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "treeClass = DecisionTreeClassifier()\n",
        "\n",
        "# Train\n",
        "treeClass = treeClass.fit(X_train,y_train)\n",
        "\n",
        "#Predict\n",
        "y_pred = treeClass.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyuQcU1VxtI8"
      },
      "source": [
        "## Accuracy of the Model\n",
        "\n",
        "To see how good our machine learning model is we need to see how accurate our predictions are. `Scikit` has built in functions and [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) to do this for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJEEykU_xtI8"
      },
      "source": [
        "print(\"Accuracy: \")\n",
        "print(metrics.accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9DDQ5q6xtI9"
      },
      "source": [
        "\n",
        "## Making Predictions\n",
        "\n",
        "Not bad. We can use our model to predict a guess for **ill** if we pass along all of the other parameters. Our model only tells us if someone is ill or not. This is directly asking our classification model to give us a prediction based on a pretend record.\n",
        "\n",
        "Since this classifier tells us if someone is ill or someone is not ill, it has two outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6eiDXHextI9"
      },
      "source": [
        "data.quality.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EyejmEXxtI9"
      },
      "source": [
        "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
        "# This is from line: 281 of the datafile\n",
        "redwine_x_quality_of_8 = [\n",
        "        10.3, #fixed acidity\n",
        "        0.32, #volatile acidity\n",
        "        0.45, #citric acid\n",
        "        6.4, #residual sugar \n",
        "        0.073, #chlorides\n",
        "        5, #free sulfur dioxide\n",
        "        13, #total sulfur dioxide\n",
        "        0.9976, #density\n",
        "        3.23, #pH\n",
        "        0.82, #sulphates\n",
        "        12.6, #alcohol\n",
        "]\n",
        "\n",
        "redwine_x_quality_of_8 = pd.DataFrame([redwine_x_quality_of_8],columns=X_test.columns)\n",
        "\n",
        "print(\"Red Wine with a quality of 8\")\n",
        "print(\"Class predicted by model: \")\n",
        "print(treeClass.predict(redwine_x_quality_of_8))\n",
        "print(\"Probablity associated with the guess: \")\n",
        "print(treeClass.predict_proba(redwine_x_quality_of_8))\n",
        "\n",
        "\n",
        "\n",
        "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
        "# This is from line: 692 of the datafile\n",
        "redwine_x_quality_of_3 = [\n",
        "        7.4, #fixed acidity\n",
        "        1.185, #volatile acidity\n",
        "        0, #citric acid\n",
        "        4.25, #residual sugar\n",
        "        0.097, #chlorides\n",
        "        5, #free sulfur dioxide\n",
        "        14, #total sulfur dioxide\n",
        "        0.9966, #density\n",
        "        3.63, #pH\n",
        "        0.54, #sulphates\n",
        "        10.7, #alcohol\n",
        "]\n",
        "\n",
        "#Use the dataframe of our fictional person in our model and get our prediction\n",
        "redwine_x_quality_of_3 = pd.DataFrame([redwine_x_quality_of_3],columns=X_test.columns)\n",
        "\n",
        "print(\"\\nRed Wine with a quality of 3\")\n",
        "print(\"Class predicted by model: \")\n",
        "print(treeClass.predict(redwine_x_quality_of_3))\n",
        "print(\"Probablity associated with the guess: \")\n",
        "print(treeClass.predict_proba(redwine_x_quality_of_3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VwVLeBfxtI9"
      },
      "source": [
        "With this model constucted we can make ask it question so to speak. We can provide it with details about a pretend person and see what classification the model will place this person.\n",
        "\n",
        "## Q1 - Making a prediction with our model\n",
        "\n",
        "Try to set some parameters in the `pretend_rw` variable below to make the prediction determine that the red wine has a quality of **8**. If you can find one please copy and paste it into the chat box for others to try. \n",
        "\n",
        "When you are done experiementing please type \"Done\" in the chat box. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmYZzuPoxtI9"
      },
      "source": [
        "pretend_rw = pd.DataFrame([\n",
        "        10.3, #fixed acidity\n",
        "        0.32, #volatile acidity\n",
        "        0.45, #citric acid\n",
        "        6.4, #residual sugar \n",
        "        0.073, #chlorides\n",
        "        5, #free sulfur dioxide\n",
        "        13, #total sulfur dioxide\n",
        "        0.9976, #density\n",
        "        8.23, #pH - choose a value between 0-14\n",
        "        0.82, #sulphates\n",
        "        12.6, #alcohol\n",
        "])\n",
        "\n",
        "\n",
        "#turn our pretend redwine into a dataframe that is the correct dimensions\n",
        "pretend_rw = pretend_rw.T \n",
        "pretend_rw.columns = X_test.columns\n",
        "\n",
        "print(\"\\Pretend redwine details\")\n",
        "print(pretend_rw.head())\n",
        "\n",
        "print(\"Pretend redwine Class predicted\")\n",
        "print(treeClass.predict(pretend_rw))\n",
        "\n",
        "print(\"Pretend redwine probablity of guess\")\n",
        "print(treeClass.predict_proba(pretend_rw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IyoKO1WxtI-"
      },
      "source": [
        "\n",
        "## Visualizing our Decision Tree\n",
        "\n",
        "We can 'visualize' the decision tree to trace through the decisions it makes. In this case we can tell that **income level** is the most important factor that we consider since we ask so many questions about that before looking at any of the other features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxPvbHujxtI-"
      },
      "source": [
        "printed_tree = export_text(treeClass, features)\n",
        "print(printed_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gms5xRhlxtI-"
      },
      "source": [
        "## Tuning parameters - Testing Set Sizes\n",
        "\n",
        "To make our models run better we can tweak _many, many, many_ different parameters. For example, we can vary the testing data size percentage. We'll try some different values and plot our our accuracy of our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qzYpbcU-xtI_"
      },
      "source": [
        "testing_percents = [1,5,10,20,30,100]\n",
        "accuracy = []\n",
        "training_percents = []\n",
        "\n",
        "for test_ratio in testing_percents:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
        "                                                        y, \\\n",
        "                                                        test_size=test_percent/100.0,\n",
        "                                                        random_state=10)\n",
        "    treeClassTest = DecisionTreeClassifier()\n",
        "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
        "    y_pred = treeClassTest.predict(X_test)\n",
        "    score = metrics.accuracy_score(y_test,y_pred)\n",
        "    accuracy.append(score)\n",
        "    training_percents.append(100 - test_ratio)\n",
        "\n",
        "    \n",
        "plt.plot(training_percents,accuracy)\n",
        "plt.ylabel(\"Accuracy in %\")\n",
        "plt.xlabel(\"Training Size %\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u16lPsGFxtI_"
      },
      "source": [
        "(Your graph might look different, this is a statistical operation and will probably vary across different machines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzrnDquFxtI_"
      },
      "source": [
        "## Tuning Parameters - Maximum depth of the tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDxBjS-JxtI_"
      },
      "source": [
        "test_percent = 70\n",
        "max_options = [5,10,15,20,25,30]\n",
        "\n",
        "accuracy = []\n",
        "tree_max = []\n",
        "\n",
        "for max_d in max_options:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
        "                                                        y, \\\n",
        "                                                        test_size=test_percent/100.0,\n",
        "                                                        random_state=10,\n",
        "                                                       )\n",
        "    \n",
        "    #We set maximum depth in the DecisionTreeClassifer when we first create the variable\n",
        "    treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
        "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
        "    y_pred = treeClassTest.predict(X_test)\n",
        "    score = metrics.accuracy_score(y_test,y_pred)\n",
        "    accuracy.append(score)\n",
        "    tree_max.append(max_d)\n",
        "\n",
        "    \n",
        "plt.plot(max_options,accuracy)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Maximum Depth of Tree\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02HEj-2liHuU"
      },
      "source": [
        "## Now try these steps on your own usng the white wine dataset\n",
        "\n",
        "First, load the white wine dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sleT6LxJik3z"
      },
      "source": [
        "white_wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",sep=';')\n",
        "white_wine\n",
        "white_wine.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAHeACbSi_LO"
      },
      "source": [
        "white_wine.columns "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08TgxISjjSRc"
      },
      "source": [
        "**Q1** Create a list of features inside the square brackets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbUKdGrki8sQ"
      },
      "source": [
        "#fill in this list\n",
        "white_wine_features = [\n",
        "            ]\n",
        "\n",
        "white_X_features = white_wine[white_wine_features]\n",
        "white_X_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtqkTc6vkOQ5"
      },
      "source": [
        "## Q2 \n",
        "\n",
        "In the chat box state what our **target** should be.\n",
        "Complete the assignment for `white_target` below once you have an answer, by adding the column name onto the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVCuCiFvkUyQ"
      },
      "source": [
        "#we're looking for the column name\n",
        "white_target = white_wine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW9JEI3Sk32E"
      },
      "source": [
        "## Q3\n",
        "Try to come up with a good testing percentage size. Share it with everyone else after you've measured your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O1cijTZlU1I"
      },
      "source": [
        "white_test_percent = \n",
        "white_train_percent = 100 - white_test_percent\n",
        "\n",
        "#Split into training testing\n",
        "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(white_X_features, \\\n",
        "                                                    white_target, \\\n",
        "                                                    test_size=white_test_percent/100.0,\n",
        "                                                   random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPL2BUl9lNpS"
      },
      "source": [
        "**Congratulations!!** You have done the most difficult part of a machine learning task. Understanding the data.\n",
        "\n",
        "Let's train our model and get our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCBN_Z93lh8b"
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "whiteTree = DecisionTreeClassifier()\n",
        "\n",
        "# Train\n",
        "whiteTree = whiteTree.fit(X_white_train,y_white_train)\n",
        "\n",
        "#Predict\n",
        "white_prediction = whiteTree.predict(X_white_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hx1DxMklqez"
      },
      "source": [
        "Let's see how accurate we are..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWimUlOLlur9"
      },
      "source": [
        "metrics.accuracy_score(y_white_test,white_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYCcX3XlhmLj"
      },
      "source": [
        "Add the .unique() function to the following code to list all the quality ratings for the white wine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofW_fCSWmn3o"
      },
      "source": [
        "sorted(white_wine[\"quality\"].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsh5vLQ5lyeH"
      },
      "source": [
        "Let's do some predictions with this tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYXETEiNmbdI"
      },
      "source": [
        "# From line 1408, 8.2;0.22;0.36;6.8;0.034;12;90;0.9944;3.01;0.38;10.5;8\n",
        "white_x_good = ([\n",
        "    8.2, #'fixed acidity'\n",
        "    0.22, #'volatile acidity'\n",
        "    0.36, #'citric acid' \n",
        "    6.8, #'residual sugar'\n",
        "    0.034, #'chlorides'\n",
        "    12, #'free sulfur dioxide'\n",
        "    100, #'total sulfur dioxide'\n",
        "    0.0, #'density'\n",
        "    0.9944, #'pH'\n",
        "    0.038, #'sulphates'\n",
        "    10.5  #'alcohol'\n",
        "])\n",
        "\n",
        "white_x_good = pd.DataFrame([white_x_good],columns=X_white_test.columns)\n",
        "whiteTree.predict_proba(white_x_good)\n",
        "\n",
        "\n",
        "print(\"\\Pretend whitewine details\")\n",
        "print(white_x_good.head())\n",
        "\n",
        "print(\"Pretend whitewine Class predicted\")\n",
        "print(whiteTree.predict(white_x_good))\n",
        "\n",
        "print(\"Pretend whitewine probablity of guess\")\n",
        "print(whiteTree.predict_proba(white_x_good))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z1rDa_yxtJD"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "We have just scratched the surface with what is possible with Python and SciKit. Remember, don't let the name **Machine Learning** fool you. Most of the time the computer is making guesses based on past data. Sometimes this works good, sometimes it doesn't work so good!"
      ]
    }
  ]
}