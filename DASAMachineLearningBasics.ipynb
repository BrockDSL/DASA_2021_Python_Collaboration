{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Machine Learning Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrockDSL/DASA_2021_Python_Collaboration/blob/main/DASAMachineLearningBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bif0tsBDxtIr"
      },
      "source": [
        "![DSL_logo](https://github.com/BrockDSL/Machine_Learning_with_Python/blob/master/dsl_logo.png?raw=1)\n",
        "\n",
        "# Introduction to Machine Learning with Python\n",
        "\n",
        "\n",
        "In our [Data Science](https://brockdsl.github.io/Python_2.0_Workshop/) workshop we introduced some concepts by looking at some fictional data about wine samples that were rated a quality score. In this session we are going to see if we can build a machine learning model to see if we can predict which wine sample is rated the highest quality based on the answers to some questions. \n",
        "\n",
        "As a further exercise we'll setup an example of a two layer neural network. I encourage you to try out this examples after class is done.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6PZm1dKxtIw"
      },
      "source": [
        "## First, a brief recap on Python code\n",
        "\n",
        "The following code should look familiar to you"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHQNPWMZxtIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d02d4d1-f220-43d9-8ef3-bbf538e2a945"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the file into a dataframe using the pandas read_csv function\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "\n",
        "#Tell it what our columns are by passing along a list of that information\n",
        "data.columns = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
        "\n",
        "print(\"Poor Quality or High Quality?\")\n",
        "print(data.groupby(\"quality\")[\"citric acid\"].count())\n",
        "print(\"\\nTotal records:\", len(data))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poor Quality or High Quality?\n",
            "quality\n",
            "3     10\n",
            "4     53\n",
            "5    681\n",
            "6    638\n",
            "7    199\n",
            "8     18\n",
            "Name: citric acid, dtype: int64\n",
            "\n",
            "Total records: 1599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xXF7W2lxtIy"
      },
      "source": [
        "## Machine Learning Basics\n",
        "\n",
        "Don't let the impressive name fool you. Machine learning is more or less the following steps\n",
        "\n",
        "1. Getting your data and cleaning it up\n",
        "1. Identify what parts of your data are **features**\n",
        "1. Identify what is your **target variable** that you'll guess based on your features\n",
        "1. Split your data in **training and testing sets**\n",
        "1. **Train** your model against the training set\n",
        "1. **Validate** your model against the testing set\n",
        "1. ????\n",
        "1. Profit\n",
        "\n",
        "\n",
        "We are going to use the Python library [scikit-learn](https://scikit-learn.org/stable/) and we are going to be doing a [classification](https://en.wikipedia.org/wiki/Statistical_classification) problem.\n",
        "\n",
        "![classification](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/classification.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV3QmkVcxtIz"
      },
      "source": [
        "## Decision Tree\n",
        "\n",
        "This is one of the most basic machine learning model you can use. It is considered a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) method. You create the best [decision tree](https://en.wikipedia.org/wiki/Decision_tree_learning) that you can based on your training data. Here's an example tree that shows your chance of surviving the Titanic disaster. What we are creating is series of question that when answered will put observations into a _bucket_ or in other terms one of the classification options. We also devise a probability associated with an observation falling into that _bucket_.\n",
        "\n",
        "The features are described by the labels, however ``sibsp`` - is the number of spouses or siblings on board.\n",
        "\n",
        "![dtree](https://upload.wikimedia.org/wikipedia/commons/e/eb/Decision_Tree.jpg)\n",
        "\n",
        "\n",
        "So in this tree the most important question to ask first is what is the gender of the person you are considering, then next most important question is age above 9 and a half, followed lastly by, does this person have less than three spouses or siblings on board.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo9ZhkUjxtI0"
      },
      "source": [
        "Let's start by loading the Libraries we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB_qUWNMxtI1"
      },
      "source": [
        "\n",
        "#This should look familar\n",
        "import pandas as pd\n",
        "#import numpy as np\n",
        "\n",
        "\n",
        "#We'll draw a graph later on\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Our 'Machine Learning pieces'\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import export_text\n",
        "from sklearn import metrics \n",
        "from sklearn import tree\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3qQyaGIxtI2"
      },
      "source": [
        "## Getting the data ready\n",
        "\n",
        "Now, let's load our data. Our decision tree can only work with numerical values, so we'll have to modify the columns of data that are text based. As stated preparing the data is usually the most difficult part of the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-D7eb-kxtI2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7b029665-869b-4400-b6ea-06e6dcf636eb"
      },
      "source": [
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "data.columns = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
        "data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK-S0JNHxtI5"
      },
      "source": [
        "## Building and Running the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYDN-8jLxtI5"
      },
      "source": [
        "We now have our data cleaned up, and represented in a way that Scikit will be able to analyze. To be honest the most difficult part of the process is done.\n",
        "\n",
        "We now need to split our columns in two types:\n",
        "- **features** represent the data we use to build our guess\n",
        "- **target variable** the thing our model hopes to guess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa1meCmOxtI6"
      },
      "source": [
        "#all of the following columns are features, we'll make a list of their names\n",
        "features = [\"fixed acidity\",\\\n",
        "            \"volatile acidity\",\\\n",
        "            \"citric acid\",\\\n",
        "            \"residual sugar\",\\\n",
        "            \"chlorides\",\n",
        "            \"free sulfur dioxide\",\\\n",
        "            \"total sulfur dioxide\",\\\n",
        "            \"density\",\n",
        "            \"pH\",\\\n",
        "            \"sulphates\",\\\n",
        "            \"alcohol\",\\\n",
        "            ]\n",
        "\n",
        "X = data[features]\n",
        "\n",
        "#We want to target the quality column\n",
        "y = data.quality"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhruO3UHxtI7"
      },
      "source": [
        "\n",
        "## Training and testing\n",
        "\n",
        "Now that we have built our model we need to get the data ready for it. We do this by breaking it into two different pieces. The diagram shows a conceptualization of how this is proportioned.\n",
        "\n",
        "![Train Test Split](https://raw.githubusercontent.com/BrockDSL/Machine_Learning_with_Python/master/train_test.png)\n",
        "\n",
        "- **Training set** this is what is used to build the model\n",
        "- **Testing set** this is used to see if our guesses are correct\n",
        "\n",
        "Before we were looking at the **columns** of the data, this investigation of training/testing looks at the **rows** of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p-MRbnwxtI7"
      },
      "source": [
        "#Training and test together make up 100% of the data!\n",
        "#We start with a baseline of 30% of our data as testing\n",
        "\n",
        "test_percent = 30\n",
        "train_percent = 100 - test_percent\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
        "                                                    y, \\\n",
        "                                                    test_size=test_percent/100.0,\n",
        "                                                   random_state=10)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjlsU2pTxtI7"
      },
      "source": [
        "Now the interesting part, we build our model, **train** it against the **training set** and see how it **predicts** against the **testing set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6malq8NxtI8"
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "treeClass = DecisionTreeClassifier()\n",
        "\n",
        "# Train\n",
        "treeClass = treeClass.fit(X_train,y_train)\n",
        "\n",
        "#Predict\n",
        "y_pred = treeClass.predict(X_test)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyuQcU1VxtI8"
      },
      "source": [
        "## Accuracy of the Model\n",
        "\n",
        "To see how good our machine learning model is we need to see how accurate our predictions are. `Scikit` has built in functions and [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) to do this for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJEEykU_xtI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c2a048-3597-46d4-b4e1-5f2eacff8007"
      },
      "source": [
        "print(\"Accuracy: \")\n",
        "print(metrics.accuracy_score(y_test,y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: \n",
            "0.60625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9DDQ5q6xtI9"
      },
      "source": [
        "\n",
        "## Making Predictions\n",
        "\n",
        "Not bad. We can use our model to predict a guess for **ill** if we pass along all of the other parameters. Our model only tells us if someone is ill or not. This is directly asking our classification model to give us a prediction based on a pretend record.\n",
        "\n",
        "Since this classifier tells us if someone is ill or someone is not ill, it has two outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6eiDXHextI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747d2389-6f84-4f55-96c0-80a7ecd2c553"
      },
      "source": [
        "data.quality.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 7, 4, 8, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EyejmEXxtI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ada1281-6ae1-4626-f49b-c2c1cfd0a267"
      },
      "source": [
        "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
        "# This is from line: 281 of the datafile\n",
        "redwine_x_quality_of_8 = [\n",
        "        10.3, #fixed acidity\n",
        "        0.32, #volatile acidity\n",
        "        0.45, #citric acid\n",
        "        6.4, #residual sugar \n",
        "        0.073, #chlorides\n",
        "        5, #free sulfur dioxide\n",
        "        13, #total sulfur dioxide\n",
        "        0.9976, #density\n",
        "        3.23, #pH\n",
        "        0.82, #sulphates\n",
        "        12.6, #alcohol\n",
        "]\n",
        "\n",
        "redwine_x_quality_of_8 = pd.DataFrame([redwine_x_quality_of_8],columns=X_test.columns)\n",
        "\n",
        "print(\"Red Wine with a quality of 8\")\n",
        "print(\"Class predicted by model: \")\n",
        "print(treeClass.predict(redwine_x_quality_of_8))\n",
        "print(\"Probablity associated with the guess: \")\n",
        "print(treeClass.predict_proba(redwine_x_quality_of_8))\n",
        "\n",
        "\n",
        "\n",
        "# I randomly picked a record in the dataset to test if the prediction is correct. \n",
        "# This is from line: 692 of the datafile\n",
        "redwine_x_quality_of_3 = [\n",
        "        7.4, #fixed acidity\n",
        "        1.185, #volatile acidity\n",
        "        0, #citric acid\n",
        "        4.25, #residual sugar\n",
        "        0.097, #chlorides\n",
        "        5, #free sulfur dioxide\n",
        "        14, #total sulfur dioxide\n",
        "        0.9966, #density\n",
        "        3.63, #pH\n",
        "        0.54, #sulphates\n",
        "        10.7, #alcohol\n",
        "]\n",
        "\n",
        "#Use the dataframe of our fictional person in our model and get our prediction\n",
        "redwine_x_quality_of_3 = pd.DataFrame([redwine_x_quality_of_3],columns=X_test.columns)\n",
        "\n",
        "print(\"\\nRed Wine with a quality of 3\")\n",
        "print(\"Class predicted by model: \")\n",
        "print(treeClass.predict(redwine_x_quality_of_3))\n",
        "print(\"Probablity associated with the guess: \")\n",
        "print(treeClass.predict_proba(redwine_x_quality_of_3))\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red Wine with a quality of 8\n",
            "Class predicted by model: \n",
            "[7]\n",
            "Probablity associated with the guess: \n",
            "[[0. 0. 0. 0. 1. 0.]]\n",
            "\n",
            "Red Wine with a quality of 3\n",
            "Class predicted by model: \n",
            "[3]\n",
            "Probablity associated with the guess: \n",
            "[[1. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VwVLeBfxtI9"
      },
      "source": [
        "With this model constucted we can make ask it question so to speak. We can provide it with details about a pretend person and see what classification the model will place this person.\n",
        "\n",
        "## Q1 - Making a prediction with our model\n",
        "\n",
        "Try to set some parameters in the `pretend_rw` variable below to make the prediction determine that the red wine has a quality of **8**. If you can find one please copy and paste it into the chat box for others to try. \n",
        "\n",
        "When you are done experiementing please type \"Done\" in the chat box. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmYZzuPoxtI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f989ae7-df76-4783-fb3f-f219d5169b37"
      },
      "source": [
        "pretend_rw = pd.DataFrame([\n",
        "        10.3, #fixed acidity\n",
        "        0.32, #volatile acidity\n",
        "        0.45, #citric acid\n",
        "        6.4, #residual sugar \n",
        "        0.073, #chlorides\n",
        "        5, #free sulfur dioxide\n",
        "        13, #total sulfur dioxide\n",
        "        0.9976, #density\n",
        "        8.23, #pH - choose a value between 0-14\n",
        "        0.82, #sulphates\n",
        "        12.6, #alcohol\n",
        "])\n",
        "\n",
        "\n",
        "#turn our pretend redwine into a dataframe that is the correct dimensions\n",
        "pretend_rw = pretend_rw.T \n",
        "pretend_rw.columns = X_test.columns\n",
        "\n",
        "print(\"\\Pretend redwine details\")\n",
        "print(pretend_rw.head())\n",
        "\n",
        "print(\"Pretend redwine Class predicted\")\n",
        "print(treeClass.predict(pretend_rw))\n",
        "\n",
        "print(\"Pretend redwine probablity of guess\")\n",
        "print(treeClass.predict_proba(pretend_rw))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\Pretend redwine details\n",
            "   fixed acidity  volatile acidity  citric acid  ...    pH  sulphates  alcohol\n",
            "0           10.3              0.32         0.45  ...  8.23       0.82     12.6\n",
            "\n",
            "[1 rows x 11 columns]\n",
            "Pretend redwine Class predicted\n",
            "[7]\n",
            "Pretend redwine probablity of guess\n",
            "[[0. 0. 0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IyoKO1WxtI-"
      },
      "source": [
        "\n",
        "## Visualizing our Decision Tree\n",
        "\n",
        "We can 'visualize' the decision tree to trace through the decisions it makes. In this case we can tell that **income level** is the most important factor that we consider since we ask so many questions about that before looking at any of the other features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxPvbHujxtI-"
      },
      "source": [
        "printed_tree = export_text(treeClass, features)\n",
        "print(printed_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gms5xRhlxtI-"
      },
      "source": [
        "## Tuning parameters - Testing Set Sizes\n",
        "\n",
        "To make our models run better we can tweak _many, many, many_ different parameters. For example, we can vary the testing data size percentage. We'll try some different values and plot our our accuracy of our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qzYpbcU-xtI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "a5bfd12b-f438-4ecf-9005-07084e68878d"
      },
      "source": [
        "testing_percents = [1,5,10,20,30,100]\n",
        "accuracy = []\n",
        "training_percents = []\n",
        "\n",
        "for test_ratio in testing_percents:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
        "                                                        y, \\\n",
        "                                                        test_size=test_percent/100.0,\n",
        "                                                        random_state=10)\n",
        "    treeClassTest = DecisionTreeClassifier()\n",
        "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
        "    y_pred = treeClassTest.predict(X_test)\n",
        "    score = metrics.accuracy_score(y_test,y_pred)\n",
        "    accuracy.append(score)\n",
        "    training_percents.append(100 - test_ratio)\n",
        "\n",
        "    \n",
        "plt.plot(training_percents,accuracy)\n",
        "plt.ylabel(\"Accuracy in %\")\n",
        "plt.xlabel(\"Training Size %\")\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u16lPsGFxtI_"
      },
      "source": [
        "(Your graph might look different, this is a statistical operation and will probably vary across different machines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzrnDquFxtI_"
      },
      "source": [
        "## Tuning Parameters - Maximum depth of the tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDxBjS-JxtI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b44efb1d-af81-4e0d-8a6b-35d77e93d752"
      },
      "source": [
        "test_percent = 70\n",
        "max_options = [5,10,15,20,25,30]\n",
        "\n",
        "accuracy = []\n",
        "tree_max = []\n",
        "\n",
        "for max_d in max_options:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, \\\n",
        "                                                        y, \\\n",
        "                                                        test_size=test_percent/100.0,\n",
        "                                                        random_state=10,\n",
        "                                                       )\n",
        "    \n",
        "    #We set maximum depth in the DecisionTreeClassifer when we first create the variable\n",
        "    treeClassTest = DecisionTreeClassifier(max_depth=max_d)\n",
        "    treeClassTest = treeClassTest.fit(X_train,y_train)\n",
        "    y_pred = treeClassTest.predict(X_test)\n",
        "    score = metrics.accuracy_score(y_test,y_pred)\n",
        "    accuracy.append(score)\n",
        "    tree_max.append(max_d)\n",
        "\n",
        "    \n",
        "plt.plot(max_options,accuracy)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Maximum Depth of Tree\")\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VWGde8VhrEX"
      },
      "source": [
        "## Using a Machine Learning Network to detect pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GV6Py1thb9Z"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg  \n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from PIL import Image\n",
        "\n",
        "# Import Fashion MNIST\n",
        "fashion_mnist = input_data.read_data_sets('input/data', \n",
        "        one_hot=True)\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) \\\n",
        "        = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', \n",
        "        'Pullover', 'Dress', 'Coat', \n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "\n",
        "# Prepare the training images\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "\n",
        "# Prepare the test images\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "input_shape = (28, 28, 1)\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                                    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# test with 10,000 images\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('10,000 image Test accuracy:', test_acc)\n",
        "\n",
        "#run test image from Fashion_MNIST data \n",
        "\n",
        "img = test_images[15]\n",
        "img = (np.expand_dims(img,0))\n",
        "singlePrediction = model.predict(img,steps=1)\n",
        "print (\"Prediction Output\")\n",
        "print(singlePrediction)\n",
        "print()\n",
        "NumberElement = singlePrediction.argmax()\n",
        "Element = np.amax(singlePrediction)\n",
        "\n",
        "print (\"Our Network has concluded that the image number '15' is a \"\n",
        "        +class_names[NumberElement])\n",
        "print (str(int(Element*100)) + \"% Confidence Level\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK1lUYn0H_UL"
      },
      "source": [
        "## Introduction to Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvrhdWblA4Hv"
      },
      "source": [
        "# 2 Layer Neural Network in NumPy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# X = input of our 3 input XOR gate\n",
        "# set up the inputs of the neural network (right from the table)\n",
        "X = np.array(([0,0,0],[0,0,1],[0,1,0], \\\n",
        "    [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)\n",
        "# y = our output of our neural network\n",
        "y = np.array(([1], [0],  [0],  [0],  [0], \\\n",
        "     [0],  [0],  [1]), dtype=float)\n",
        "\n",
        "# what value we want to predict\n",
        "xPredicted = np.array(([0,0,1]), dtype=float)\n",
        "\n",
        "X = X/np.amax(X, axis=0) # maximum of X input array\n",
        "# maximum of xPredicted (our input data for the prediction)\n",
        "xPredicted = xPredicted/np.amax(xPredicted, axis=0) \n",
        "\n",
        "# set up our Loss file for graphing\n",
        "\n",
        "lossFile = open(\"SumSquaredLossList.csv\", \"w\")\n",
        "\n",
        "class Neural_Network (object):\n",
        "  def __init__(self):\n",
        "    #parameters\n",
        "    self.inputLayerSize = 3  # X1,X2,X3 \n",
        "    self.outputLayerSize = 1 # Y1\n",
        "    self.hiddenLayerSize = 4 # Size of the hidden layer\n",
        "\n",
        "    # build weights of each layer\n",
        "    # set to random values\n",
        "    # look at the interconnection diagram to make sense of this\n",
        "    # 3x4 matrix for input to hidden\n",
        "    self.W1 = \\\n",
        "            np.random.randn(self.inputLayerSize, self.hiddenLayerSize) \n",
        "    # 4x1 matrix for hidden layer to output\n",
        "    self.W2 = \\\n",
        "            np.random.randn(self.hiddenLayerSize, self.outputLayerSize) \n",
        "\n",
        "  def feedForward(self, X):\n",
        "    # feedForward propagation through our network\n",
        "    # dot product of X (input) and first set of 3x4  weights\n",
        "    self.z = np.dot(X, self.W1) \n",
        "\n",
        "    # the activationSigmoid activation function - neural magic\n",
        "    self.z2 = self.activationSigmoid(self.z) \n",
        "\n",
        "    # dot product of hidden layer (z2) and second set of 4x1 weights\n",
        "    self.z3 = np.dot(self.z2, self.W2) \n",
        "\n",
        "    # final activation function - more neural magic\n",
        "    o = self.activationSigmoid(self.z3) \n",
        "    return o\n",
        "\n",
        "  def backwardPropagate(self, X, y, o):\n",
        "    # backward propagate through the network\n",
        "    # calculate the error in output\n",
        "    self.o_error = y - o \n",
        "\n",
        "    # apply derivative of activationSigmoid to error\n",
        "    self.o_delta = self.o_error*self.activationSigmoidPrime(o) \n",
        "\n",
        "    # z2 error: how much our hidden layer weights contributed to output error\n",
        "    self.z2_error = self.o_delta.dot(self.W2.T) \n",
        "\n",
        "    # applying derivative of activationSigmoid to z2 error\n",
        "    self.z2_delta = self.z2_error*self.activationSigmoidPrime(self.z2) \n",
        "\n",
        "    # adjusting first set (inputLayer --> hiddenLayer) weights\n",
        "    self.W1 += X.T.dot(self.z2_delta) \n",
        "    # adjusting second set (hiddenLayer --> outputLayer) weights \n",
        "    self.W2 += self.z2.T.dot(self.o_delta) \n",
        "\n",
        "  def trainNetwork(self, X, y):\n",
        "    # feed forward the loop\n",
        "    o = self.feedForward(X)\n",
        "    # and then back propagate the values (feedback)\n",
        "    self.backwardPropagate(X, y, o)\n",
        "\n",
        "\n",
        "  def activationSigmoid(self, s):\n",
        "    # activation function\n",
        "    # simple activationSigmoid curve as in the book\n",
        "    return 1/(1+np.exp(-s))\n",
        "\n",
        "  def activationSigmoidPrime(self, s):\n",
        "    # First derivative of activationSigmoid\n",
        "    # calculus time!\n",
        "    return s * (1 - s)\n",
        "\n",
        "\n",
        "  def saveSumSquaredLossList(self,i,error):\n",
        "    lossFile.write(str(i)+\",\"+str(error.tolist())+'\\n')\n",
        "    \n",
        "  def saveWeights(self):\n",
        "    # save this in order to reproduce our cool network\n",
        "    np.savetxt(\"weightsLayer1.txt\", self.W1, fmt=\"%s\")\n",
        "    np.savetxt(\"weightsLayer2.txt\", self.W2, fmt=\"%s\")\n",
        "\n",
        "  def predictOutput(self):\n",
        "    print (\"Predicted XOR output data based on trained weights: \")\n",
        "    print (\"Expected (X1-X3): \\n\" + str(xPredicted))\n",
        "    print (\"Output (Y1): \\n\" + str(self.feedForward(xPredicted)))\n",
        "\n",
        "myNeuralNetwork = Neural_Network()\n",
        "trainingEpochs = 1000\n",
        "#trainingEpochs = 100000\n",
        "\n",
        "for i in range(trainingEpochs): # train myNeuralNetwork 1,000 times\n",
        "  print (\"Epoch # \" + str(i) + \"\\n\")\n",
        "  print (\"Network Input : \\n\" + str(X))\n",
        "  print (\"Expected Output of XOR Gate Neural Network: \\n\" + str(y))\n",
        "  print (\"Actual  Output from XOR Gate Neural Network: \\n\" + \\\n",
        "          str(myNeuralNetwork.feedForward(X)))\n",
        "  # mean sum squared loss\n",
        "  Loss = np.mean(np.square(y - myNeuralNetwork.feedForward(X))) \n",
        "  myNeuralNetwork.saveSumSquaredLossList(i,Loss)\n",
        "  print (\"Sum Squared Loss: \\n\" + str(Loss))\n",
        "  print (\"\\n\")\n",
        "  myNeuralNetwork.trainNetwork(X, y)\n",
        "\n",
        "myNeuralNetwork.saveWeights()\n",
        "myNeuralNetwork.predictOutput()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z1rDa_yxtJD"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "We have just scratched the surface with what is possible with Python and SciKit. Remember, don't let the name **Machine Learning** fool you. Most of the time the computer is making guesses based on past data. Sometimes this works good, sometimes it doesn't work so good!"
      ]
    }
  ]
}